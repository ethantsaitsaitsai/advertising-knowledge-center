"""
AKC Framework 3.0 - Data Analyst Agent (V2)
Implemented using langchain.agents.create_agent
"""
import json
from datetime import datetime
from typing import Dict, Any, List, Optional

from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import wrap_tool_call, dynamic_prompt, ModelRequest
from langchain.messages import SystemMessage, ToolMessage, AIMessage, HumanMessage
from langchain_core.messages import BaseMessage

from config.llm import llm
from agent.state import AgentState as ProjectAgentState
from tools.entity_resolver import resolve_entity
from tools.campaign_template_tool import (
    query_campaign_basic,
    query_budget_details,
    query_investment_budget,
    query_execution_budget,
    query_targeting_segments,
    query_ad_formats,
    execute_sql_template,
    query_industry_format_budget
)
from tools.performance_tools import query_performance_metrics, query_format_benchmark

# Tools for Retrieval
RETRIEVER_TOOLS = [
    resolve_entity,
    query_campaign_basic,
    query_budget_details,
    query_investment_budget,
    query_execution_budget,
    query_targeting_segments,
    query_ad_formats,
    execute_sql_template,
    query_industry_format_budget,
    query_performance_metrics,
    query_format_benchmark
]

RETRIEVER_SYSTEM_PROMPT = """‰Ω†ÊòØ AKC Êô∫ËÉΩÂä©ÊâãÁöÑÊï∏ÊìöÊ™¢Á¥¢Â∞àÂÆ∂ (Data Retriever)„ÄÇ

**‰Ω†ÁöÑ‰ªªÂãôÊµÅÁ®ã (SOP)**:

**‚ö†Ô∏è ÈóúÈçµÂà§Êñ∑Ôºö‰ΩïÊôÇ‰ΩøÁî®„ÄåÁµ±Ë®àËàáÂü∫Ê∫ñÂ∑•ÂÖ∑„ÄçÔºü**
Ëã•‰ΩøÁî®ËÄÖÁöÑÂïèÈ°åÂ±¨Êñº„ÄåÂÖ®Á´ô/Áî¢Ê•≠Â±§Á¥ö„ÄçÁöÑ„Äå‰ΩîÊØî„ÄçÊàñ„ÄåÊéíÂêç„ÄçÂàÜÊûêÔºå**Ë´ãÂÑ™ÂÖà‰ΩøÁî®‰ª•‰∏ãÈ´òÊïàÂ∑•ÂÖ∑**Ôºå‰∏¶Ë∑≥ÈÅéÂæåÁ∫åÁöÑÂØ¶È´îËß£ÊûêËàáÊ¥ªÂãïÊü•Ë©¢Ê≠•È©üÔºö

1. **Â§öÁ∂≠Â∫¶È†êÁÆó‰ΩîÊØî (`query_industry_format_budget`)**:
   - ÈÅ©Áî®Ôºö„ÄåÊüêÁî¢Ê•≠ÁöÑÊ†ºÂºèÂàÜ‰Ωà„Äç„ÄÅ„ÄåÊüêÊ†ºÂºèÁöÑÁî¢Ê•≠ÂàÜ‰Ωà„Äç„ÄÅ„ÄåÊüêÊ†ºÂºèÁöÑÂÆ¢Êà∂ÂàÜ‰Ωà„Äç„ÄÇ
   - **Ê†∏ÂøÉÂèÉÊï∏ `dimension` (Ê±∫ÂÆöÂàÜÊûêË¶ñËßí)**:
     - Êü•„ÄåÁî¢Ê•≠È†êÁÆó„ÄçÊàñ„ÄåÊäïÊîæÂì™‰∫õÊ†ºÂºè„Äç‚Üí Êé®Ëñ¶‰ΩøÁî® `dimension='sub_industry'` (Â≠êÈ°û) ‰ª•Áç≤ÂæóÊõ¥Á¥∞Á∑ªÁöÑÂàÜÊûê (Ëã•ÁÑ°ÁâπÂÆöÈúÄÊ±Ç‰πüÂèØÈÅ∏ `dimension='industry'` Â§ßÈ°û)„ÄÇ
     - Êü•„ÄåÂÆ¢Êà∂È†êÁÆó„ÄçÊàñ„ÄåË™∞Êäï‰∫ÜÈÄôÂÄãÊ†ºÂºè„Äç‚Üí `dimension='client'`
     - Êü•„Äå‰ª£ÁêÜÂïÜÈ†êÁÆó„Äç‚Üí `dimension='agency'`
   - **Ê†∏ÂøÉÂèÉÊï∏ `primary_view` (Ê±∫ÂÆö‰∏ªÈ´îËàáÁ¨¨‰∏ÄÊ¨Ñ)**:
     - `'dimension'` (È†êË®≠): ‰ª•„ÄåÁî¢Ê•≠/ÂÆ¢Êà∂„ÄçÁÇ∫‰∏ªÈ´î„ÄÇÁ¨¨‰∏ÄÊ¨ÑÈ°ØÁ§∫Áî¢Ê•≠ÔºåÈÅ©Áî®Êñº„ÄåÊüêÁî¢Ê•≠Êäï‰∫Ü‰ªÄÈ∫º„Äç„ÄÇ
     - `'format'`: ‰ª•„ÄåÊ†ºÂºè„ÄçÁÇ∫‰∏ªÈ´î„ÄÇÁ¨¨‰∏ÄÊ¨ÑÈ°ØÁ§∫Ê†ºÂºèÔºåÈÅ©Áî®Êñº„ÄåÊüêÊ†ºÂºèÊäïÂà∞‰∫ÜÂì™Ë£°„ÄçÊàñ„ÄåÊâÄÊúâÊ†ºÂºèÁöÑË°®Áèæ„Äç„ÄÇ
   - **ÈÅéÊøæÂèÉÊï∏**:
     - Ëã•ÊåáÂÆöÁâπÂÆöÊ†ºÂºè (Â¶Ç„ÄåBanner„Äç)ÔºåË´ãË®≠ `format_ids` (ÈúÄÂÖàÈÄèÈÅé `resolve_entity` ÂèñÂæóÊ†ºÂºè ID)„ÄÇ

2. **ÂÖ®Á´ôÊ†ºÂºèÊàêÊïà (`query_format_benchmark`)**:
   - **ÈÅ©Áî®Â†¥ÊôØ** (ÈÄôÊòØÂ∞àÈñÄÁî®ÊñºÊ†ºÂºèÊàêÊïàÊéíÂêçÁöÑÂ∑•ÂÖ∑):
     - „ÄåÊâÄÊúâÊ†ºÂºèÁöÑ CTR ÊéíÂêç„Äç
     - „ÄåÊ±ΩËªäÁî¢Ê•≠ÊâÄÊúâÊ†ºÂºèÁöÑ VTR Âπ≥Âùá„Äç
     - „ÄåÊüêÂÄãÊ†ºÂºèÂú®ÂÖ®Á´ôÁöÑÊàêÊïàË°®Áèæ„Äç
   - **‰ΩøÁî®Ë¶èÂâá**:
     - ‚ö†Ô∏è **ÈóúÈçµÂà§Êñ∑**: Â¶ÇÊûú‰ΩøÁî®ËÄÖÊü•Ë©¢ÂêåÊôÇÂåÖÂê´„ÄåÊ†ºÂºè„ÄçÂíå„ÄåÊàêÊïàÊåáÊ®ô (CTR/VTR/ER/ÈªûÊìäÁéá/ËßÄÁúãÁéá)„Äç,**ÂøÖÈ†àÂÑ™ÂÖàËÄÉÊÖÆ‰ΩøÁî®Ê≠§Â∑•ÂÖ∑**
     - **ÂèÉÊï∏Ë™™Êòé**:
       - `cmp_ids` (ÂèØÈÅ∏): Â¶ÇÊûúË¶ÅÊü•Ë©¢ÁâπÂÆöÁî¢Ê•≠/ÂÆ¢Êà∂ÁöÑÊ†ºÂºèÊàêÊïà,Ë´ãÂÇ≥ÂÖ• campaign_ids (ÈúÄÂÖàÈÄèÈÅé `query_campaign_basic` ÂèñÂæó)
       - `format_ids` (ÂèØÈÅ∏): Â¶ÇÊûúË¶ÅÊü•Ë©¢ÁâπÂÆöÊ†ºÂºèÁöÑÊàêÊïà,Ë´ãÂÇ≥ÂÖ• format_ids (ÈúÄÂÖàÈÄèÈÅé `resolve_entity` ÂèñÂæó)
       - Â¶ÇÊûúÂÖ©ËÄÖÈÉΩ‰∏çÂÇ≥,ÂâáËøîÂõû„ÄåÂÖ®Á´ôÊâÄÊúâÊ†ºÂºè„ÄçÁöÑÊàêÊïàÂü∫Ê∫ñ
   - **Âü∑Ë°åÈ†ÜÂ∫è** (ÈáùÂ∞çÁî¢Ê•≠Êü•Ë©¢):
     1. ‰ΩøÁî® `resolve_entity` Ëß£ÊûêÁî¢Ê•≠ÂêçÁ®± ‚Üí ÂèñÂæóÁî¢Ê•≠ ID
     2. ‰ΩøÁî® `query_campaign_basic` ÂèñÂæóË©≤Áî¢Ê•≠ÁöÑÊâÄÊúâÊ¥ªÂãï ‚Üí ÂèñÂæó campaign_ids ÂàóË°®
     3. ‰ΩøÁî® `query_format_benchmark(cmp_ids=[...])` Êü•Ë©¢Ë©≤Áî¢Ê•≠ÁöÑÊ†ºÂºèÊàêÊïà

---

**‰∏ÄËà¨Êü•Ë©¢ÊµÅÁ®ã (ÈáùÂ∞çÁâπÂÆöÂØ¶È´î/Campaign)**:

**‚ö†Ô∏è ÈóúÈçµÂà§Êñ∑Ôºö‰ΩïÊôÇÈúÄË¶ÅÂØ¶È´îËß£ÊûêÔºü**
Âú®Âü∑Ë°å Step 1 ‰πãÂâçÔºåË´ãÂÖàÂà§Êñ∑‰ΩøÁî®ËÄÖÊü•Ë©¢ÁöÑÈ°ûÂûãÔºö

- **ÈúÄË¶ÅÂØ¶È´îËß£ÊûêÁöÑÊü•Ë©¢** (‰ΩøÁî® `resolve_entity`):
  - ‰ΩøÁî®ËÄÖÊèêÂà∞**ÂÖ∑È´îÁöÑÂêçÁ®±**Ôºå‰æãÂ¶ÇÔºö"ÊÇ†ÈÅäÂç°ÁöÑÈ†êÁÆó"„ÄÅ"ÁæéÂ¶ùÁî¢Ê•≠ÁöÑÊ¥ªÂãï"„ÄÇ

- **‰∏çÈúÄË¶ÅÂØ¶È´îËß£ÊûêÁöÑÊü•Ë©¢** (Áõ¥Êé•ÈÄ≤ÂÖ• Step 3):
  - ‰ΩøÁî®ËÄÖË¶ÅÊ±Ç**Êï¥È´îÊéíÂêç/ÂåØÁ∏Ω/Áµ±Ë®à**Ôºå‰æãÂ¶ÇÔºö"‰ª£ÁêÜÂïÜ YTD Ë™çÂàóÈáëÈ°ç"„ÄÅ"ÂâçÂçÅÂ§ßÂÆ¢Êà∂ÁöÑÊäïË≥á"„ÄÇ

1. **ÂØ¶È´îËß£Êûê (Step 1 - ÂÉÖÂú®ÈúÄË¶ÅÊôÇÂü∑Ë°å)**:
   - **Âè™ÊúâÂú®‰ΩøÁî®ËÄÖÊèêÂà∞ÂÖ∑È´îÂêçÁ®±ÊôÇ**ÔºåÊâç‰ΩøÁî® `resolve_entity` Â∞áÂêçÁ®±ËΩâÊèõÁÇ∫ ID„ÄÇ
   - **‚ö†Ô∏è RAG ÁµêÊûúËôïÁêÜ**: Ëã• `resolve_entity` ÂõûÂÇ≥ `rag_results` (Ê®°Á≥äÊêúÂ∞ã)ÔºåÈÄô‰∫õÁµêÊûú**‰∏çÂê´ ID**„ÄÇ‰Ω†**ÂøÖÈ†à**ÈÅ∏ÊìáÊúÄÁõ∏ÈóúÁöÑ‰∏ÄÂÄãÂêçÁ®±Ôºå**ÂÜçÊ¨°ÂëºÂè´** `resolve_entity` ‰ª•ÂèñÂæóÁ≤æÁ¢∫ ID (`exact_match`)„ÄÇ

2. **Áç≤ÂèñÊ¥ªÂãï (Step 2 - ÂÉÖÂú® Step 1 Âü∑Ë°åÂæå)**:
   - **ÊÉÖÊ≥Å A: ÂØ¶È´îÊòØ„ÄåÂÆ¢Êà∂ (Client)„ÄçÊàñ„ÄåÂìÅÁâå (Brand)„Äç**:
     - **ÂèñÂæó ID ÂæåÔºåÁ´ãÂàª** ‰ΩøÁî® `query_campaign_basic` ÂèñÂæóË©≤ÂÆ¢Êà∂ÁöÑÊâÄÊúâÊ¥ªÂãïÂàóË°®„ÄÇ
   - **ÊÉÖÊ≥Å B: ÂØ¶È´îÊòØ„ÄåÁî¢Ê•≠ (Industry/Sub-industry)„Äç**:
     - **Ëã•Êü• È†êÁÆó/ÈáëÈ°ç/ÂàÜ‰Ωà** (`query_industry_format_budget`): Ê≠§Â∑•ÂÖ∑ÂÖßÂª∫Áî¢Ê•≠ÁØ©ÈÅ∏Ôºå**Ë´ãË∑≥ÈÅé Step 2**ÔºåÁõ¥Êé•Âü∑Ë°å Step 3„ÄÇ
     - **Ëã•Êü• ÊàêÊïà/CTR/ÊéíÂêç** (`query_performance_metrics` Êàñ `query_format_benchmark`): ÈÄô‰∫õÂ∑•ÂÖ∑ÈúÄË¶Å Campaign IDs„ÄÇ**ÂøÖÈ†àÂü∑Ë°å Step 2** (`query_campaign_basic`) ÂèñÂæóË©≤Áî¢Ê•≠ÁöÑÊ¥ªÂãïÂàóË°®ÔºåÂÜçÂ∞á IDs ÂÇ≥ÂÖ•ÊàêÊïàÂ∑•ÂÖ∑„ÄÇ

3. **Êï∏ÊìöËíêÈõÜ (Step 3 - ÊâÄÊúâÊü•Ë©¢ÈÉΩÈúÄË¶Å)**:
   - Ê†πÊìö‰ΩøÁî®ËÄÖÈúÄÊ±ÇÔºåÂëºÂè´ÈÅ©Áï∂ÁöÑÊü•Ë©¢Â∑•ÂÖ∑Ôºö
     - `query_execution_budget`: Êü•Ë©¢„ÄåË™çÂàóÈáëÈ°ç„ÄçÊàñ„ÄåÂü∑Ë°åÈáëÈ°ç„Äç
     - `query_investment_budget`: Êü•Ë©¢„ÄåÈ†êÁÆó„ÄçÊàñ„ÄåÈÄ≤ÂñÆÈáëÈ°ç„Äç
     - `query_performance_metrics`: Êü•Ë©¢ÊàêÊïà (ÂøÖÈ†àÂÇ≥ÂÖ• `cmp_ids`)
     - `query_targeting_segments`: Êü•Ë©¢ÂèóÁúæ
     - `query_ad_formats`: Êü•Ë©¢Âª£ÂëäÊ†ºÂºè

   - **‚ö†Ô∏è ÂÆ¢Êà∂Á¥öÂà•ÊàêÊïàÊü•Ë©¢ (ÈáçË¶Å)**:
     - Â¶ÇÊûú‰ΩøÁî®ËÄÖË¶ÅÊ±Ç„ÄåÂêÑÊ†ºÂºèÁöÑÂÆ¢Êà∂ÊéíÂêç (‰æùÊàêÊïà)„Äç„ÄÅ„ÄåÂì™‰∫õÂÆ¢Êà∂ÁöÑ CTR ÊúÄÈ´ò„ÄçÁ≠âÊü•Ë©¢:
       1. **ÂøÖÈ†àÂêåÊôÇË™øÁî®ÂÖ©ÂÄãÂ∑•ÂÖ∑**:
          - `query_performance_metrics`: Áç≤Âèñ campaign ÁöÑÊàêÊïàÊï∏Êìö
          - `query_campaign_basic`: Áç≤Âèñ campaign ÁöÑÂÆ¢Êà∂‰ø°ÊÅØ
       2. Reporter ÊúÉËá™ÂãïÂêà‰ΩµÈÄôÂÖ©ÂÄãÊï∏ÊìöÈõÜ‰∏¶ÊåâÂÆ¢Êà∂ËÅöÂêà

**Ê†∏ÂøÉÂéüÂâá (ÈêµÂæã)**:
- **ID ÁµïÂ∞çÂÑ™ÂÖà**: Âè™Ë¶Å‰Ω†ÂèñÂæó‰∫Ü IDÔºåÂæåÁ∫åÊâÄÊúâÊü•Ë©¢ **ÂøÖÈ†à** ‰ΩøÁî® ID„ÄÇ
- **ÊàêÊïàÊü•Ë©¢Ë¶èÁØÑ**: ÂøÖÈ†àÂÇ≥ÂÖ• `cmp_ids`„ÄÇË´ãË®≠ÂÆöÂØ¨È¨ÜÁöÑÊôÇÈñìÁØÑÂúç (‰æãÂ¶Ç `start_date='2021-01-01'`) ‰ª•Áç≤ÂèñÊ≠∑Âè≤Êï∏Êìö„ÄÇ

**ÁµêÊùüÊ¢ù‰ª∂**:
- Áï∂‰Ω†Êî∂ÈõÜÂÆåÊâÄÊúâÂøÖË¶ÅÁöÑÊï∏ÊìöÔºåË´ãÂÅúÊ≠¢ÂëºÂè´Â∑•ÂÖ∑Ôºå‰∏¶Á∞°ÂñÆÂõûË¶ÜÔºö„ÄåÊï∏ÊìöÊî∂ÈõÜÂÆåÁï¢ÔºåËΩâ‰∫§Â†±ÂëäËÄÖËôïÁêÜ„ÄÇ„Äç
- ‚ö†Ô∏è **Á¶ÅÊ≠¢ÊèêÊó©ÁµêÊùü**: ÁµïÂ∞ç‰∏çËÉΩÂú®Âè™ÂëºÂè´ `resolve_entity` ÂæåÂ∞±ÂÅúÊ≠¢„ÄÇ‰Ω†ÂøÖÈ†àËá≥Â∞ëÂëºÂè´‰∏ÄÊ¨°Êï∏ÊìöÊü•Ë©¢Â∑•ÂÖ∑ (Â¶Ç `query_industry_format_budget`, `query_performance_metrics` Á≠â) ÊãøÂà∞Êï∏ÂÄºË≥áÊñô„ÄÇ
"""

@dynamic_prompt
def retriever_dynamic_prompt(request: ModelRequest) -> str:
    """Injects current date and resolved entities into the system prompt."""
    now = datetime.now()
    current_date = now.strftime("%Y-%m-%d")
    
    base_prompt = RETRIEVER_SYSTEM_PROMPT.format(current_date=current_date)
    
    # In-context learning for resolved entities
    resolved_entities = request.state.get("resolved_entities", [])
    if resolved_entities:
        context_lines = []
        for e in resolved_entities:
            e_type = e.get('type', 'unknown')
            e_id = e.get('id')
            e_name = e.get('name')
            context_lines.append(f"- {e_type.upper()} ID: {e_id} (ÂêçÁ®±: {e_name})")

        entity_context = "\n\nÂ∑≤Á¢∫Ë™çÁöÑÂØ¶È´îË≥áË®äÔºö\n" + "\n".join(context_lines)
        return base_prompt + entity_context
    
    return base_prompt

@wrap_tool_call
def retriever_tool_middleware(request: Any, handler):
    """
    Middleware to handle:
    1. Data storage in state['data_store']
    2. Custom guidance for Entity Resolution and Campaign queries
    3. Debug logging
    """
    tool_call = request.tool_call
    tool_name = tool_call["name"]
    args = tool_call["args"]
    state = request.state
    
    # Initialize state fields if needed
    if "data_store" not in state or state["data_store"] is None:
        state["data_store"] = {}
    if "debug_logs" not in state or state["debug_logs"] is None:
        state["debug_logs"] = []
    if "resolved_entities" not in state or state["resolved_entities"] is None:
        state["resolved_entities"] = []

    try:
        # Execute tool
        result = handler(request)
        
        # Extract raw data from result
        raw_result = None
        if isinstance(result, ToolMessage):
            content = result.content
            try:
                raw_result = json.loads(content)
            except:
                try:
                    import ast
                    # Handle Decimal inside string representation
                    # e.g. "{'amt': Decimal('10.5')}" -> "{'amt': 10.5}"
                    # Simple regex replace might be safer than eval with context
                    import re
                    # Replace Decimal('123.45') with 123.45
                    cleaned = re.sub(r"Decimal\('([^']+)'\)", r"\1", content)
                    # Replace datetime.date(2023, 1, 1) with '2023-01-01'
                    cleaned = re.sub(r"datetime\.date\((\d+), (\d+), (\d+)\)", r"'\1-\2-\3'", cleaned)
                    # Replace datetime.datetime(2023, 1, 1, 12, 0) with '2023-01-01T12:00:00'
                    # Handle optional time components (simple greedy match might be risky, stick to basic pattern)
                    cleaned = re.sub(r"datetime\.datetime\((\d+), (\d+), (\d+),? ?(\d+)?,? ?(\d+)?,? ?(\d+)?\)", 
                                     lambda m: f"'{m.group(1)}-{m.group(2)}-{m.group(3)}'", cleaned) # Simplify to date for now or improve regex
                    
                    raw_result = ast.literal_eval(cleaned)
                except Exception as parse_e:
                    print(f"DEBUG [RetrieverMiddleware] Failed to parse content for {tool_name}: {parse_e}")
                    print(f"DEBUG [RetrieverMiddleware] Content preview: {content[:200]}...")
        elif isinstance(result, dict):
            raw_result = result
            
        if raw_result and isinstance(raw_result, dict):
            # 1. Logic to store data (with Deduplication)
            if "data" in raw_result:
                data = raw_result.get("data")
                if data and isinstance(data, list) and len(data) > 0:
                    if tool_name not in state["data_store"]:
                        state["data_store"][tool_name] = []

                    # Deduplicate
                    existing_data_str = {json.dumps(row, sort_keys=True, default=str) for row in state["data_store"][tool_name]}
                    new_rows = []
                    for row in data:
                        row_str = json.dumps(row, sort_keys=True, default=str)
                        if row_str not in existing_data_str:
                            new_rows.append(row)
                            existing_data_str.add(row_str)

                    if new_rows:
                        state["data_store"][tool_name].extend(new_rows)
                        print(f"DEBUG [RetrieverMiddleware] Stored {len(new_rows)} rows in data_store")
            
            # 2. Handle Entity Resolution specifically for state update
            if tool_name == "resolve_entity":
                status = raw_result.get("status")
                if status in ["exact_match", "merged_match"]:
                    entity = raw_result.get("data")
                    if isinstance(entity, list):
                        state["resolved_entities"].extend(entity)
                    else:
                        state["resolved_entities"].append(entity)
                print(f"DEBUG [RetrieverMiddleware] Updated resolved_entities: {len(state['resolved_entities'])}")

            # 3. Add guidance and convert to valid JSON
            # Use a custom encoder/default function to handle Decimals/Dates safely
            def json_default(obj):
                import decimal
                import datetime
                if isinstance(obj, decimal.Decimal):
                    return float(obj)
                if isinstance(obj, (datetime.date, datetime.datetime)):
                    return obj.isoformat()
                return str(obj)

            content = json.dumps(raw_result, ensure_ascii=False, default=json_default)
            
            # Add guidance for query_campaign_basic
            if tool_name == "query_campaign_basic" and raw_result.get("data"):
                campaign_ids = [row.get('campaign_id') for row in raw_result.get("data", []) if row.get('campaign_id')]
                if campaign_ids:
                    content += f"\n\n‚úÖ Â∑≤ÂèñÂæó {len(campaign_ids)} ÂÄãÊ¥ªÂãïÁöÑÂü∫Êú¨Ë≥áÊñô„ÄÇ\nüëâ ‰∏ã‰∏ÄÊ≠•: Ë´ãÊü•Ë©¢ÊàêÊïà/È†êÁÆóÁ≠âÊï∏Êìö„ÄÇ"
            
            # 4. Return as ToolMessage to ensure JSON format
            return ToolMessage(tool_call_id=tool_call["id"], content=content)

        return result
    except Exception as e:
        print(f"ERROR [RetrieverMiddleware] {e}")
        return ToolMessage(tool_call_id=tool_call["id"], content=json.dumps({"error": str(e)}))

# Create the agent
retriever_agent = create_agent(
    model=llm,
    tools=RETRIEVER_TOOLS,
    middleware=[retriever_dynamic_prompt, retriever_tool_middleware],
    state_schema=ProjectAgentState
)

def _check_performance_tools_needed(state: ProjectAgentState, result: Dict[str, Any]) -> Dict[str, bool]:
    """
    Ê™¢Êü•ÊòØÂê¶ÈúÄË¶ÅË™øÁî®ÊàêÊïàÁõ∏ÈóúÂ∑•ÂÖ∑„ÄÇ

    Returns:
        {
            "needs_benchmark": bool,  # ÊòØÂê¶ÈúÄË¶Å query_format_benchmark
            "needs_performance": bool,  # ÊòØÂê¶ÈúÄË¶Å query_performance_metrics
            "needs_campaign_basic": bool  # ÊòØÂê¶ÈúÄË¶Å query_campaign_basic
        }
    """
    original_query = state.get("routing_context", {}).get("original_query", "").lower()

    # Ê™¢Êü•ÊòØÂê¶ÂåÖÂê´Ê†ºÂºèÁõ∏ÈóúÈóúÈçµÂ≠ó
    format_keywords = ["Ê†ºÂºè", "format", "banner", "ÂΩ±Èü≥", "Âª£ÂëäÂΩ¢Âºè"]
    has_format = any(kw in original_query for kw in format_keywords)

    # Ê™¢Êü•ÊòØÂê¶ÂåÖÂê´ÊàêÊïàÊåáÊ®ôÈóúÈçµÂ≠ó
    performance_keywords = ["ctr", "vtr", "er", "ÈªûÊìäÁéá", "ËßÄÁúãÁéá", "‰∫íÂãïÁéá", "ÊàêÊïà", "ÊéíÂêç", "Âπ≥Âùá"]
    has_performance = any(kw in original_query for kw in performance_keywords)

    # Ê™¢Êü•ÊòØÂê¶ÂåÖÂê´ÂÆ¢Êà∂Áõ∏ÈóúÈóúÈçµÂ≠ó
    client_keywords = ["ÂÆ¢Êà∂", "client", "Âª£Âëä‰∏ª", "ÂìÅÁâå"]
    has_client = any(kw in original_query for kw in client_keywords)

    # Ê™¢Êü•Â∑≤Ë™øÁî®ÁöÑÂ∑•ÂÖ∑
    messages = result.get("messages", [])
    data_store = result.get("data_store", {})

    has_benchmark = "query_format_benchmark" in data_store
    has_performance = "query_performance_metrics" in data_store
    has_campaign_basic = "query_campaign_basic" in data_store

    needs = {
        "needs_benchmark": False,
        "needs_performance": False,
        "needs_campaign_basic": False
    }

    # Â†¥ÊôØÂà§Êñ∑
    if has_format and has_performance:
        if has_client:
            # Â†¥ÊôØ: ÂÆ¢Êà∂Á¥öÂà•ÊàêÊïàÊü•Ë©¢ (ÈúÄË¶Å performance + campaign_basic)
            needs["needs_performance"] = not has_performance
            needs["needs_campaign_basic"] = not has_campaign_basic
        else:
            # Â†¥ÊôØ: Ê†ºÂºèÊàêÊïàÊü•Ë©¢ (ÈúÄË¶Å benchmark)
            needs["needs_benchmark"] = not has_benchmark

    return needs

def data_retriever_v2_node(state: ProjectAgentState) -> Dict[str, Any]:
    """
    Wrapper for the retriever_agent to be used as a node in analyst_graph.
    """
    # Calculate starting counts to determine new items
    initial_messages_count = len(state.get("messages", []))
    initial_logs_count = len(state.get("debug_logs", []))
    
    # [NEW] Sanitize messages: Convert dicts to Objects locally
    # This prevents LangChain from choking on dicts without dirtying the global state with duplicates
    sanitized_messages = []
    for msg in state.get("messages", []):
        if isinstance(msg, dict):
            msg_type = msg.get("type", "human")
            content = msg.get("content", "")
            if msg_type == "human":
                sanitized_messages.append(HumanMessage(content=content))
            elif msg_type == "ai":
                sanitized_messages.append(AIMessage(content=content))
            elif msg_type == "system":
                sanitized_messages.append(SystemMessage(content=content))
            elif msg_type == "tool":
                # Handle tool messages from dict if needed
                tool_call_id = msg.get("tool_call_id", "unknown")
                sanitized_messages.append(ToolMessage(content=content, tool_call_id=tool_call_id))
            else:
                # Fallback for unknown dict types
                sanitized_messages.append(HumanMessage(content=str(msg)))
        elif isinstance(msg, BaseMessage):
            # Check for generic BaseMessage and convert to HumanMessage if it's not a specific type
            # Google GenAI strictly requires specific message types
            if msg.type == "human":
                sanitized_messages.append(HumanMessage(content=msg.content))
            elif msg.type == "ai":
                sanitized_messages.append(AIMessage(content=msg.content))
            elif msg.type == "system":
                sanitized_messages.append(SystemMessage(content=msg.content))
            elif msg.type == "tool":
                sanitized_messages.append(msg) # ToolMessage is usually fine
            else:
                # If it's a generic BaseMessage without a clear type, treat as HumanMessage
                sanitized_messages.append(HumanMessage(content=msg.content))
        else:
            # Fallback for any other object
            sanitized_messages.append(HumanMessage(content=str(msg)))
            
    # Create a local state copy with sanitized messages
    local_state = state.copy()
    local_state["messages"] = sanitized_messages

    # Run the agent with sanitized state
    result = retriever_agent.invoke(local_state)
    
    # Extract only new items to avoid duplication with operator.add
    final_messages = result.get("messages", [])
    new_messages = final_messages[len(sanitized_messages):] # Diff based on sanitized input length
    
    final_logs = result.get("debug_logs", [])
    new_logs = final_logs[initial_logs_count:]
    
    # [NEW] Post-execution validation: Check if performance tools should be called
    needs = _check_performance_tools_needed(state, result)

    # Get date range from routing_context
    routing_context = state.get("routing_context", {})
    start_date = routing_context.get("start_date", "2021-01-01")
    end_date = routing_context.get("end_date", datetime.now().strftime("%Y-%m-%d"))

    # Initialize data_store if needed
    if "data_store" not in result:
        result["data_store"] = {}

    # Auto-invoke missing tools
    if needs.get("needs_benchmark"):
        print("‚ö†Ô∏è [RetrieverValidator] Detected missing query_format_benchmark call. Auto-invoking...")
        try:
            # Extract campaign_ids from data_store (if available)
            campaign_data = result.get("data_store", {}).get("query_campaign_basic", [])
            cmp_ids = [row.get('campaign_id') for row in campaign_data if row.get('campaign_id')] if campaign_data else None

            invoke_params = {
                "start_date": start_date,
                "end_date": end_date
            }
            if cmp_ids:
                invoke_params["cmp_ids"] = cmp_ids
                print(f"‚ö†Ô∏è [RetrieverValidator] Auto-invoking benchmark with {len(cmp_ids)} campaign IDs")
            else:
                print(f"‚ö†Ô∏è [RetrieverValidator] Auto-invoking benchmark for ÂÖ®Á´ôÊü•Ë©¢")

            benchmark_result = query_format_benchmark.invoke(invoke_params)

            if benchmark_result.get("status") == "success" and benchmark_result.get("data"):
                result["data_store"]["query_format_benchmark"] = benchmark_result.get("data", [])
                print(f"‚úÖ [RetrieverValidator] Auto-invoked query_format_benchmark, got {len(benchmark_result.get('data', []))} rows")
        except Exception as e:
            print(f"‚ö†Ô∏è [RetrieverValidator] Auto-invoke benchmark failed: {e}")

    if needs.get("needs_performance") or needs.get("needs_campaign_basic"):
        print("‚ö†Ô∏è [RetrieverValidator] Detected client-level performance query. Auto-invoking required tools...")

        # For client-level performance queries, we need ALL campaigns
        if needs.get("needs_campaign_basic"):
            print("‚ö†Ô∏è [RetrieverValidator] Auto-invoking query_campaign_basic for ÂÖ®Á´ôÂÆ¢Êà∂")
            try:
                # Query all campaigns (no filter)
                campaign_result = query_campaign_basic.invoke({
                    "start_date": start_date,
                    "end_date": end_date
                })
                if campaign_result.get("status") == "success" and campaign_result.get("data"):
                    result["data_store"]["query_campaign_basic"] = campaign_result.get("data", [])
                    print(f"‚úÖ [RetrieverValidator] Auto-invoked query_campaign_basic, got {len(campaign_result.get('data', []))} campaigns")
            except Exception as e:
                print(f"‚ö†Ô∏è [RetrieverValidator] Auto-invoke campaign_basic failed: {e}")

        if needs.get("needs_performance"):
            campaign_data = result.get("data_store", {}).get("query_campaign_basic", [])
            cmp_ids = [row.get('campaign_id') for row in campaign_data if row.get('campaign_id')]

            if cmp_ids:
                print(f"‚ö†Ô∏è [RetrieverValidator] Auto-invoking query_performance_metrics with {len(cmp_ids)} campaign IDs")
                try:
                    performance_result = query_performance_metrics.invoke({
                        "start_date": start_date,
                        "end_date": end_date,
                        "cmp_ids": cmp_ids,
                        "dimension": "format"
                    })
                    if performance_result.get("status") == "success" and performance_result.get("data"):
                        result["data_store"]["query_performance_metrics"] = performance_result.get("data", [])
                        print(f"‚úÖ [RetrieverValidator] Auto-invoked query_performance_metrics, got {len(performance_result.get('data', []))} rows")
                except Exception as e:
                    print(f"‚ö†Ô∏è [RetrieverValidator] Auto-invoke performance_metrics failed: {e}")
            else:
                print(f"‚ö†Ô∏è [RetrieverValidator] Cannot invoke query_performance_metrics: no campaign IDs available")

    # Construct output update
    output = {
        "messages": new_messages,
        "debug_logs": new_logs,
        # data_store and resolved_entities are typically overwritten or merged by logic,
        # but since they don't have reducers in AgentState (or might not), passing full object is safer/required
        "data_store": result.get("data_store"),
        "resolved_entities": result.get("resolved_entities")
    }

    return output
