"""
Data Retriever Node for AKC Framework 3.0

Responsibilities:
1. Resolve Entities (Names -> IDs)
2. Execute SQL Queries (MySQL & ClickHouse)
3. Store raw results in state['data_store']
4. Pass control to DataReporter
"""
from typing import Dict, Any, List
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from config.llm import llm
from agent.state import AgentState
from tools.entity_resolver import resolve_entity
from tools.campaign_template_tool import (
    query_campaign_basic,
    query_budget_details,
    query_investment_budget,
    query_execution_budget,
    query_targeting_segments,
    query_ad_formats,
    execute_sql_template,
    query_industry_format_budget
)
from tools.performance_tools import query_performance_metrics, query_format_benchmark
import json
from datetime import datetime

# Tools for Retrieval ONLY (No Pandas)
RETRIEVER_TOOLS = [
    resolve_entity,
    query_campaign_basic,
    query_budget_details,
    query_investment_budget,
    query_execution_budget,
    query_targeting_segments,
    query_ad_formats,
    execute_sql_template,
    query_industry_format_budget,
    query_performance_metrics,
    query_format_benchmark
]

# Bind tools
llm_with_tools = llm.bind_tools(RETRIEVER_TOOLS)

RETRIEVER_SYSTEM_PROMPT = """ä½ æ˜¯ AKC æ™ºèƒ½åŠ©æ‰‹çš„æ•¸æ“šæª¢ç´¢å°ˆå®¶ (Data Retriever)ã€‚

**ä½ çš„ä»»å‹™æµç¨‹ (SOP)**:

**âš ï¸ é—œéµåˆ¤æ–·ï¼šä½•æ™‚ä½¿ç”¨ã€Œçµ±è¨ˆèˆ‡åŸºæº–å·¥å…·ã€ï¼Ÿ**
è‹¥ä½¿ç”¨è€…çš„å•é¡Œå±¬æ–¼ã€Œå…¨ç«™/ç”¢æ¥­å±¤ç´šã€çš„ã€Œä½”æ¯”ã€æˆ–ã€Œæ’åã€åˆ†æï¼Œ**è«‹å„ªå…ˆä½¿ç”¨ä»¥ä¸‹é«˜æ•ˆå·¥å…·**ï¼Œä¸¦è·³éå¾ŒçºŒçš„å¯¦é«”è§£æèˆ‡æ´»å‹•æŸ¥è©¢æ­¥é©Ÿï¼š

1. **å¤šç¶­åº¦é ç®—ä½”æ¯” (`query_industry_format_budget`)**:
   - é©ç”¨ï¼šã€ŒæŸç”¢æ¥­çš„æ ¼å¼åˆ†ä½ˆã€ã€ã€ŒæŸæ ¼å¼çš„ç”¢æ¥­åˆ†ä½ˆã€ã€ã€ŒæŸæ ¼å¼çš„å®¢æˆ¶åˆ†ä½ˆã€ã€‚
   - **æ ¸å¿ƒåƒæ•¸ `dimension` (æ±ºå®šåˆ†æè¦–è§’)**:
     - æŸ¥ã€Œç”¢æ¥­é ç®—ã€æˆ–ã€ŒæŠ•æ”¾å“ªäº›æ ¼å¼ã€â†’ `dimension='industry'` (å¤§é¡) æˆ– `dimension='sub_industry'` (å­é¡ï¼Œè‹¥éœ€è¦æ›´ç´°ç·»çš„ç”¢æ¥­åˆ†ææ™‚æ¨è–¦ä½¿ç”¨)
     - æŸ¥ã€Œå®¢æˆ¶é ç®—ã€æˆ–ã€Œèª°æŠ•äº†é€™å€‹æ ¼å¼ã€â†’ `dimension='client'`
     - æŸ¥ã€Œä»£ç†å•†é ç®—ã€â†’ `dimension='agency'`
   - **æ ¸å¿ƒåƒæ•¸ `split_by_format` (æ±ºå®šèšåˆç¨‹åº¦)**:
     - `True` (é è¨­): é¡¯ç¤ºæ ¼å¼ç´°ç¯€ (ä¾‹å¦‚: æ±½è»Š-Banner, æ±½è»Š-Video) -> **é©ç”¨æ–¼ã€Œæ‰€æœ‰æ ¼å¼...ã€æˆ–ã€Œå„æ ¼å¼...ã€çš„è©³ç´°åˆ†æ**ã€‚
     - `False`: åƒ…é¡¯ç¤ºç¶­åº¦ç¸½è¨ˆ (ä¾‹å¦‚: æ±½è»Šç¸½é¡) -> é©ç”¨æ–¼ã€Œç´”ç”¢æ¥­æ’åã€ä¸”ä¸é—œå¿ƒæ ¼å¼æ™‚ã€‚
   - **æ ¸å¿ƒåƒæ•¸ `primary_view` (æ±ºå®šæ¬„ä½é †åº)**:
     - `'dimension'` (é è¨­): ç¬¬ä¸€æ¬„ç‚ºç”¢æ¥­/å®¢æˆ¶ã€‚
     - `'format'`: ç¬¬ä¸€æ¬„ç‚ºæ ¼å¼ã€‚**ç•¶ä½¿ç”¨è€…å•ã€Œæ‰€æœ‰æ ¼å¼æŠ•æ”¾åˆ°çš„...ã€æˆ–ã€ŒBanner æŠ•æ”¾åˆ°çš„...ã€æ™‚ï¼Œè«‹å‹™å¿…è¨­ç‚º `'format'`**ã€‚
   - **éæ¿¾åƒæ•¸**:
     - è‹¥æŒ‡å®šç‰¹å®šæ ¼å¼ (å¦‚ã€ŒBannerã€)ï¼Œè«‹è¨­ `format_ids` (éœ€å…ˆé€é `resolve_entity` å–å¾—æ ¼å¼ ID)ã€‚
   - **ç¯„ä¾‹**:
     - "åŠå¹´å…§æ‰€æœ‰æ ¼å¼æŠ•æ”¾çš„ç”¢æ¥­" (æ ¼å¼è¦–è§’) â†’ `query_industry_format_budget(dimension='industry', split_by_format=True, primary_view='format', ...)`
     - "æ±½è»Šç”¢æ¥­æŠ•äº†å“ªäº›æ ¼å¼" (ç”¢æ¥­è¦–è§’) â†’ `query_industry_format_budget(dimension='industry', split_by_format=True, primary_view='dimension', industry_ids=[...])`

2. **å…¨ç«™æ ¼å¼æˆæ•ˆ (`query_format_benchmark`)**:
   - é©ç”¨ï¼šã€Œæ‰€æœ‰æ ¼å¼çš„ CTR æ’åã€ã€ã€Œç”¢æ¥­çš„å¹³å‡ VTRã€ã€‚
   - ç¯„ä¾‹: "åŠå¹´å…§æ‰€æœ‰æ ¼å¼çš„ CTR æ’å" â†’ `query_format_benchmark(start_date=..., end_date=...)`

---

**ä¸€èˆ¬æŸ¥è©¢æµç¨‹ (é‡å°ç‰¹å®šå¯¦é«”/Campaign)**:

**âš ï¸ é—œéµåˆ¤æ–·ï¼šä½•æ™‚éœ€è¦å¯¦é«”è§£æï¼Ÿ**
åœ¨åŸ·è¡Œ Step 1 ä¹‹å‰ï¼Œè«‹å…ˆåˆ¤æ–·ä½¿ç”¨è€…æŸ¥è©¢çš„é¡å‹ï¼š

- **éœ€è¦å¯¦é«”è§£æçš„æŸ¥è©¢** (ä½¿ç”¨ `resolve_entity`):
  - ä½¿ç”¨è€…æåˆ°**å…·é«”çš„åç¨±**ï¼Œä¾‹å¦‚ï¼š
    - "æ‚ éŠå¡çš„é ç®—" (å…·é«”å®¢æˆ¶å)
    - "å°ç£è™èˆªçš„ä»£ç†å•†" (å…·é«”å®¢æˆ¶å)
    - "ç¾å¦ç”¢æ¥­çš„æ´»å‹•" (å…·é«”ç”¢æ¥­å)
    - "Outstream æ ¼å¼çš„åˆ†ä½ˆ" (å…·é«”æ ¼å¼å)

- **ä¸éœ€è¦å¯¦é«”è§£æçš„æŸ¥è©¢** (ç›´æ¥é€²å…¥ Step 3):
  - ä½¿ç”¨è€…è¦æ±‚**æ•´é«”æ’å/åŒ¯ç¸½/çµ±è¨ˆ**ï¼Œä¾‹å¦‚ï¼š
    - "ä»£ç†å•† YTD èªåˆ—é‡‘é¡" â†’ é€™æ˜¯è¦æ‰€æœ‰ä»£ç†å•†çš„é‡‘é¡ï¼Œ**ä¸éœ€è¦** `resolve_entity`
    - "å‰åå¤§å®¢æˆ¶çš„æŠ•è³‡" â†’ é€™æ˜¯è¦æ’åï¼Œ**ä¸éœ€è¦** `resolve_entity`
    - "å„ç”¢æ¥­çš„æˆæ•ˆæ¯”è¼ƒ" â†’ é€™æ˜¯è¦åŒ¯ç¸½ï¼Œ**ä¸éœ€è¦** `resolve_entity`
  - é—œéµå­—è­˜åˆ¥ï¼šã€Œæ‰€æœ‰ã€ã€Œå„ã€ã€Œå‰Xã€ã€ŒTop Xã€ã€Œæ’åã€ã€ŒåŒ¯ç¸½ã€ã€Œçµ±è¨ˆã€

1. **å¯¦é«”è§£æ (Step 1 - åƒ…åœ¨éœ€è¦æ™‚åŸ·è¡Œ)**:
   - **åªæœ‰åœ¨ä½¿ç”¨è€…æåˆ°å…·é«”åç¨±æ™‚**ï¼Œæ‰ä½¿ç”¨ `resolve_entity` å°‡åç¨± (å¦‚ "æ‚ éŠå¡") è½‰æ›ç‚º IDã€‚
   - **å¦‚æœæ˜¯åŒ¯ç¸½/æ’åæŸ¥è©¢**ï¼Œè«‹è·³éæ­¤æ­¥é©Ÿï¼Œç›´æ¥é€²å…¥ Step 3ã€‚

2. **ç²å–æ´»å‹• (Step 2 - åƒ…åœ¨ Step 1 åŸ·è¡Œå¾Œ)**:
   - **å–å¾— ID å¾Œï¼Œç«‹åˆ»** ä½¿ç”¨ `query_campaign_basic(client_ids=[ID])` å–å¾—è©²å®¢æˆ¶çš„æ‰€æœ‰æ´»å‹•åˆ—è¡¨ã€‚

3. **æ•¸æ“šè’é›† (Step 3 - æ‰€æœ‰æŸ¥è©¢éƒ½éœ€è¦)**:
   - æ ¹æ“šä½¿ç”¨è€…éœ€æ±‚ï¼Œå‘¼å«é©ç•¶çš„æŸ¥è©¢å·¥å…·ï¼š
     - `query_execution_budget`: æŸ¥è©¢ã€Œèªåˆ—é‡‘é¡ã€æˆ–ã€ŒåŸ·è¡Œé‡‘é¡ã€
     - `query_investment_budget`: æŸ¥è©¢ã€Œé ç®—ã€æˆ–ã€Œé€²å–®é‡‘é¡ã€
     - `query_performance_metrics`: æŸ¥è©¢æˆæ•ˆ (å¿…é ˆå‚³å…¥ `cmp_ids`)
     - `query_targeting_segments`: æŸ¥è©¢å—çœ¾
     - `query_ad_formats`: **æŸ¥è©¢å»£å‘Šæ ¼å¼ (âš ï¸ ç•¶ä½¿ç”¨è€…å•åˆ°ã€Œæ ¼å¼ã€æ™‚ï¼Œé€™æ˜¯å¿…é ˆå‘¼å«çš„å·¥å…·)**
   - **åŒ¯ç¸½æŸ¥è©¢æ™‚çš„åƒæ•¸è¨­å®š**ï¼š
     - å¦‚æœæ˜¯ã€Œä»£ç†å•†ã€ç›¸é—œæŸ¥è©¢ï¼Œä½¿ç”¨ `query_execution_budget` (æœ‰ agency_name æ¬„ä½)
     - å¦‚æœæ˜¯ã€Œç”¢æ¥­ã€ç›¸é—œæŸ¥è©¢ï¼Œä½¿ç”¨ `industry_ids` æˆ– `sub_industry_ids` åƒæ•¸
     - å¦‚æœæ˜¯ã€Œå®¢æˆ¶ã€ç›¸é—œæŸ¥è©¢ï¼Œå¯ä»¥ä¸å¸¶ä»»ä½•éæ¿¾æ¢ä»¶ï¼Œè®“ Reporter åšèšåˆ
     - **âš ï¸ é‡è¦ - LIMIT è¨­å®šç­–ç•¥**ï¼š
       - ç•¶ç”¨æˆ¶è¦æ±‚ã€Œå‰Nåã€æ™‚ï¼ŒSQL æŸ¥è©¢çš„ `limit` æ‡‰è¨­ç‚º **N Ã— 50**ï¼ˆä¾‹å¦‚ï¼šå‰20å â†’ limit=1000ï¼‰
       - åŸå› ï¼šSQL è¿”å›çš„æ˜¯æ˜ç´°è¨˜éŒ„ï¼Œéœ€è¦è¶³å¤ çš„è¨˜éŒ„æ‰èƒ½èšåˆå‡ºNå€‹åˆ†çµ„
       - ä¸€èˆ¬åŒ¯ç¸½æŸ¥è©¢ï¼šè¨­å®š `limit=5000`ï¼Œç¢ºä¿ç²å–å®Œæ•´æ•¸æ“š

**ç•¶å‰æ—¥æœŸ**: {current_date}

**æ ¸å¿ƒåŸå‰‡ (éµå¾‹)**:
- **ID çµ•å°å„ªå…ˆ**: åªè¦ä½ å–å¾—äº† `client_id` (ä¾‹å¦‚ 1453)ï¼Œå¾ŒçºŒæ‰€æœ‰æŸ¥è©¢ **å¿…é ˆ** ä½¿ç”¨ `client_ids=[1453]`ã€‚ç¦æ­¢å†ä½¿ç”¨ `client_names`ã€‚
- **é˜²æ­¢é¬¼æ‰“ç‰†**: å¦‚æœç³»çµ±æç¤ºã€Œå·²ç¢ºèªå¯¦é«”è³‡è¨Šã€ï¼Œ**è«‹ä¸è¦** å†æ¬¡å‘¼å« `resolve_entity`ï¼Œç›´æ¥é€²å…¥ Step 2ã€‚
- **æˆæ•ˆæŸ¥è©¢è¦ç¯„**:
  - æŸ¥è©¢æˆæ•ˆ (`query_performance_metrics`) æ™‚ï¼Œ**å¿…é ˆ** å‚³å…¥ `cmp_ids`ã€‚
  - **é‡è¦**: æŸ¥è©¢æ­·å²æ´»å‹•æˆæ•ˆæ™‚ï¼Œè«‹å‹™å¿…è¨­å®šå¯¬é¬†çš„æ™‚é–“ç¯„åœ (ä¾‹å¦‚ `start_date='2021-01-01'`)ï¼Œä»¥å…å› é è¨­æ™‚é–“ç¯„åœ (æœ€è¿‘ 3 å€‹æœˆ) è€Œå°è‡´æ­·å²æ•¸æ“šéºå¤±ã€‚

**çµæŸæ¢ä»¶**:
- ç•¶ä½ æ”¶é›†å®Œæ‰€æœ‰å¿…è¦çš„æ•¸æ“š (é ç®—ã€æˆæ•ˆã€æ ¼å¼ç­‰)ï¼Œè«‹åœæ­¢å‘¼å«å·¥å…·ï¼Œä¸¦ç°¡å–®å›è¦†ï¼šã€Œæ•¸æ“šæ”¶é›†å®Œç•¢ï¼Œè½‰äº¤å ±å‘Šè€…è™•ç†ã€‚ã€
"""

def data_retriever_node(state: AgentState) -> Dict[str, Any]:
    """
    Executes retrieval loop and accumulates data in state['data_store'].
    """
    # Initialize context
    now = datetime.now()
    current_date = now.strftime("%Y-%m-%d")

    routing_context = state.get("routing_context", {})
    original_query = routing_context.get("original_query", "")
    entity_keywords = routing_context.get("entity_keywords", [])

    # Initialize or Load Data Store
    data_store = state.get("data_store") or {}
    resolved_entities = state.get("resolved_entities") or []
    execution_logs = state.get("debug_logs") or []

    print(f"DEBUG [Retriever] Starting retrieval for: {original_query[:50]}...")

    # Build Messages
    messages = [
        SystemMessage(content=RETRIEVER_SYSTEM_PROMPT.format(current_date=current_date)),
        HumanMessage(content=f"æŸ¥è©¢è«‹æ±‚: {original_query}\nå¯¦é«”æç¤º: {entity_keywords}")
    ]

    # Re-inject resolved entities context if any
    if resolved_entities:
        context_lines = []
        for e in resolved_entities:
            e_type = e.get('type', 'unknown')
            e_id = e.get('id')
            e_name = e.get('name')
            context_lines.append(f"- {e_type.upper()} ID: {e_id} (åç¨±: {e_name})")

        entity_context = "å·²ç¢ºèªçš„å¯¦é«”è³‡è¨Šï¼š\n" + "\n".join(context_lines)
        messages.append(SystemMessage(content=entity_context))

    # Agent Loop
    tool_call_history = set()

    for i in range(10): # Max 10 steps for retrieval
        print(f"DEBUG [Retriever] Step {i+1}")
        response = llm_with_tools.invoke(messages)
        messages.append(response)

        if not response.tool_calls:
            print("DEBUG [Retriever] No more tool calls. Retrieval finished.")
            break

        for tool_call in response.tool_calls:
            tool_name = tool_call["name"]
            args = tool_call["args"]

            # 1. Skip if duplicate call
            call_key = f"{tool_name}:{json.dumps(args, sort_keys=True)}"
            if call_key in tool_call_history:
                print(f"DEBUG [Retriever] Skipping duplicate call: {call_key}")
                messages.append(ToolMessage(tool_call_id=tool_call["id"], content="Notice: This query was already executed. Skipping."))
                continue
            tool_call_history.add(call_key)

            # Execute
            tool_map = {t.name: t for t in RETRIEVER_TOOLS}
            func = tool_map.get(tool_name)

            if not func:
                messages.append(ToolMessage(tool_call_id=tool_call["id"], content="Error: Tool not found"))
                continue

            try:
                print(f"DEBUG [Retriever] Calling {tool_name} with {args}")
                result = func.invoke(args)

                # 2. Logic to store data (with Deduplication)
                if isinstance(result, dict) and "data" in result:
                    data = result.get("data")
                    if data and isinstance(data, list) and len(data) > 0:
                        if tool_name not in data_store:
                            data_store[tool_name] = []

                        # Deduplicate: Only add rows that aren't already there
                        existing_data_str = {json.dumps(row, sort_keys=True, default=str) for row in data_store[tool_name]}
                        new_rows = []
                        for row in data:
                            row_str = json.dumps(row, sort_keys=True, default=str)
                            if row_str not in existing_data_str:
                                new_rows.append(row)
                                existing_data_str.add(row_str)

                        if new_rows:
                            data_store[tool_name].extend(new_rows)
                            print(f"DEBUG [Retriever] Stored {len(new_rows)} NEW rows from {tool_name}")
                        else:
                            print(f"DEBUG [Retriever] All rows from {tool_name} were duplicates. Skipped.")

                        # Handle Entity Resolution specifically
                        if tool_name == "resolve_entity":
                            status = result.get("status")

                            # ===== Handle Needs Confirmation =====
                            if status == "needs_confirmation":
                                candidates = result.get("data", [])
                                if candidates:
                                    # Auto-select the first candidate to avoid blocking the flow
                                    # In production, this would be where user selection happens
                                    selected = candidates[0]
                                    print(f"âš ï¸ [Retriever] Found {len(candidates)} candidates, auto-selecting: {selected.get('name')}")

                                    # Convert to merged_match format so the flow continues
                                    result = {
                                        "status": "merged_match",
                                        "data": candidates,  # Return all candidates for potential future use
                                        "message": f"âš ï¸ Auto-selected: {selected.get('name')} from {len(candidates)} candidates",
                                        "source": "auto_selection"
                                    }
                                    # Update status variable so the next elif will match
                                    status = "merged_match"

                            # ===== Handle Exact Match / Merged Match =====
                            if status in ["exact_match", "merged_match"]:
                                entity = result.get("data")
                                if isinstance(entity, list):
                                    resolved_entities.extend(entity)
                                    # Create entity-type-aware guidance for multiple entities
                                    guidance = []
                                    entity_ids = []
                                    entity_types = set()
                                    for e in entity:
                                        guidance.append(f"{e.get('name')} (ID: {e.get('id')})")
                                        entity_ids.append(e.get('id'))
                                        entity_types.add(e.get('type'))

                                    # Determine appropriate parameter based on entity type
                                    if "industry" in entity_types:
                                        param_name = "industry_ids"
                                    elif "sub_industry" in entity_types:
                                        param_name = "sub_industry_ids"
                                    elif "campaign" in entity_types:
                                        # Skip Step 2, already have campaign IDs
                                        guide_msg = f"âœ… å·²æˆåŠŸè§£æå¯¦é«”: {', '.join(guidance)}ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥ (Step 3): å·²å–å¾— campaign IDsï¼Œè«‹ç›´æ¥æŸ¥è©¢æˆæ•ˆ/é ç®—/æ ¼å¼ç­‰æ•¸æ“šï¼Œä½¿ç”¨åƒæ•¸ `campaign_ids={json.dumps(entity_ids)}`ã€‚"
                                        messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))
                                        continue
                                    else:  # client, brand, agency
                                        param_name = "client_ids"

                                    guide_msg = f"âœ… å·²æˆåŠŸè§£æå¯¦é«”: {', '.join(guidance)}ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥ (Step 2): è«‹ç«‹åˆ»å‘¼å« `query_campaign_basic`ï¼Œä¸¦ä½¿ç”¨åƒæ•¸ `{param_name}={json.dumps(entity_ids)}`ã€‚\nğŸ“‹ æ¥ä¸‹ä¾† (Step 3): å–å¾—æ´»å‹•åˆ—è¡¨å¾Œï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…æŸ¥è©¢éœ€æ±‚ï¼Œå‘¼å« `query_ad_formats` (æŸ¥è©¢æ ¼å¼) å’Œ `query_performance_metrics` (æŸ¥è©¢æˆæ•ˆæ•¸æ“š)ã€‚"
                                    messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))
                                else:
                                    resolved_entities.append(entity)
                                    # Create entity-type-aware guidance for single entity
                                    e_id = entity.get('id')
                                    e_name = entity.get('name')
                                    e_type = entity.get('type')

                                    # Determine appropriate parameter based on entity type
                                    if e_type == "industry":
                                        param_name = "industry_ids"
                                    elif e_type == "sub_industry":
                                        param_name = "sub_industry_ids"
                                    elif e_type == "campaign":
                                        # Skip Step 2, already have campaign ID
                                        guide_msg = f"âœ… å·²æˆåŠŸè§£æå¯¦é«”: {e_name} (ID: {e_id})ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥ (Step 3): å·²å–å¾— campaign IDï¼Œè«‹ç›´æ¥æŸ¥è©¢æˆæ•ˆ/é ç®—/æ ¼å¼ç­‰æ•¸æ“šï¼Œä½¿ç”¨åƒæ•¸ `campaign_ids=[{e_id}]`ã€‚"
                                        messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))
                                        continue
                                    else:  # client, brand, agency
                                        param_name = "client_ids"

                                    guide_msg = f"âœ… å·²æˆåŠŸè§£æå¯¦é«”: {e_name} (ID: {e_id})ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥ (Step 2): è«‹ç«‹åˆ»å‘¼å« `query_campaign_basic`ï¼Œä¸¦ä½¿ç”¨åƒæ•¸ `{param_name}=[{e_id}]`ã€‚\nğŸ“‹ æ¥ä¸‹ä¾† (Step 3): å–å¾—æ´»å‹•åˆ—è¡¨å¾Œï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…æŸ¥è©¢éœ€æ±‚ï¼Œå‘¼å« `query_ad_formats` (æŸ¥è©¢æ ¼å¼) å’Œ `query_performance_metrics` (æŸ¥è©¢æˆæ•ˆæ•¸æ“š)ã€‚"
                                    messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))

                            # ===== Handle RAG Results =====
                            elif status == "rag_results":
                                rag_data = result.get("data", [])
                                if rag_data and isinstance(rag_data, list):
                                    # RAG è¿”å›çš„æ˜¯ {value, source, table, filter_type, score} æ ¼å¼
                                    # é¸æ“‡æœ€é«˜åˆ†çš„çµæœä¸¦ç›´æ¥ä½¿ç”¨åç¨±æŸ¥è©¢

                                    # å¾ filter_type æ˜ å°„åˆ°å¯¦é«”é¡å‹å’Œåƒæ•¸åç¨±
                                    filter_type_map = {
                                        "sub_industries": ("sub_industry", "sub_industry_ids"),
                                        "industries": ("industry", "industry_ids"),
                                        "advertisers": ("client", "client_ids"),
                                        "brands": ("brand", "client_ids"),
                                        "agencies": ("agency", "client_ids"),
                                        "campaigns": ("campaign", "campaign_ids")
                                    }

                                    # æ™ºèƒ½é¸æ“‡çµæœï¼šå„ªå…ˆé¸æ“‡ industry/sub_industry é¡å‹
                                    # åŸå› ï¼šç”¢æ¥­æŸ¥è©¢é€šå¸¸æ›´ç¬¦åˆä½¿ç”¨è€…æ„åœ–ï¼Œä¸”å¯ä»¥ç›´æ¥é€²å…¥æ•¸æ“šæŸ¥è©¢éšæ®µ
                                    priority_types = ['industries', 'sub_industries']
                                    priority_results = [r for r in rag_data if r.get('filter_type') in priority_types]

                                    if priority_results:
                                        # å¾å„ªå…ˆé¡å‹ä¸­é¸æ“‡æœ€é«˜åˆ†
                                        top_result = max(priority_results, key=lambda x: x.get('score', 0))
                                        print(f"DEBUG [Retriever] Smart RAG selection: Prioritized {top_result.get('filter_type')} type")
                                    else:
                                        # æ²’æœ‰å„ªå…ˆé¡å‹ï¼Œå›é€€åˆ°å…¨å±€æœ€é«˜åˆ†
                                        top_result = max(rag_data, key=lambda x: x.get('score', 0))
                                        print(f"DEBUG [Retriever] Smart RAG selection: Fallback to highest score")

                                    filter_type = top_result.get('filter_type')

                                    if filter_type in filter_type_map:
                                        entity_type, param_name = filter_type_map[filter_type]
                                        entity_value = top_result.get('value')

                                        # æ”¹é€²çš„ RAG å¼•å°ç­–ç•¥ï¼š
                                        # 1. å¦‚æœæ˜¯ industry/sub_industryï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨åç¨±æŸ¥è©¢ï¼ˆä¸éœ€è¦ IDï¼‰
                                        # 2. å¦å‰‡ï¼Œå¼•å° LLM å†æ¬¡èª¿ç”¨ resolve_entity

                                        if entity_type in ["industry", "sub_industry"]:
                                            # ç”¢æ¥­é¡å‹ï¼šå…ˆå˜—è©¦ç²å–ç²¾ç¢º IDï¼Œå¦‚æœå¤±æ•—å‰‡ç›´æ¥æŸ¥è©¢æ•¸æ“š
                                            guide_msg = f"ğŸ” RAG æ‰¾åˆ°ç›¸é—œç”¢æ¥­: {entity_value} (é¡å‹: {entity_type}, åˆ†æ•¸: {top_result.get('score'):.2f})ã€‚\n\nğŸ‘‰ **CRITICAL - è«‹ç«‹å³åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿ**ï¼š\n\n**Step 1**: å˜—è©¦å–å¾—ç²¾ç¢º IDï¼ˆå–®æ¬¡å˜—è©¦ï¼‰\n```\nresolve_entity(keyword='{entity_value}', target_types=['{entity_type}'])\n```\n\n**Step 2**: ç„¡è«– Step 1 æˆåŠŸèˆ‡å¦ï¼Œç«‹å³æŸ¥è©¢æ´»å‹•æ•¸æ“š\n```\nquery_campaign_basic()  # ä½¿ç”¨ Step 1 å–å¾—çš„ industry_ids æˆ– sub_industry_ids\n```\n\n**Step 3**: å¾ Step 2 çµæœæå– campaign_idsï¼Œç„¶å¾Œ**ä¾ç…§ä½¿ç”¨è€…æŸ¥è©¢éœ€æ±‚**ç«‹å³å‘¼å«ï¼š\n\nâš ï¸ **å¿…é ˆæ ¹æ“šä½¿ç”¨è€…æŸ¥è©¢é—œéµå­—æ±ºå®šè¦å‘¼å«å“ªäº›å·¥å…·**ï¼š\n\n- å¦‚æœæåˆ°ã€Œæ ¼å¼ã€ã€Œå»£å‘Šæ ¼å¼ã€ã€Œformatã€ â†’ å¿…é ˆå‘¼å«ï¼š\n```\nquery_ad_formats(campaign_ids=[...])\n```\n\n- å¦‚æœæåˆ°ã€Œé ç®—ã€ã€ŒæŠ•è³‡é‡‘é¡ã€ã€Œinvestmentã€ â†’ å¿…é ˆå‘¼å«ï¼š\n```\nquery_investment_budget(campaign_ids=[...])\n```\n\n- å¦‚æœæåˆ°ã€Œèªåˆ—é‡‘é¡ã€ã€ŒåŸ·è¡Œé‡‘é¡ã€ã€Œexecutionã€ â†’ å¿…é ˆå‘¼å«ï¼š\n```\nquery_execution_budget(campaign_ids=[...])\n```\n\n- å¦‚æœæåˆ°ã€Œæˆæ•ˆã€ã€ŒCTRã€ã€ŒVTRã€ã€ŒERã€ã€Œé»æ“Šç‡ã€ã€Œè§€çœ‹ç‡ã€ã€Œperformanceã€ â†’ å¿…é ˆå‘¼å«ï¼š\n```\nquery_performance_metrics(campaign_ids=[...])\n```\n\n- å¦‚æœæåˆ°ã€Œå—çœ¾ã€ã€Œæ•¸æ“šé–å®šã€ã€Œtargetingã€ã€Œsegmentã€ â†’ å¿…é ˆå‘¼å«ï¼š\n```\nquery_targeting_segments(campaign_ids=[...])\n```\n\nğŸš¨ **ç¯„ä¾‹**ï¼š\nå¦‚æœä½¿ç”¨è€…å•ã€Œæ±½è»Šç”¢æ¥­æˆæ•ˆæœ€å¥½çš„æ ¼å¼ï¼Œä»¥åŠä»–ä½¿ç”¨äº†ä»€éº¼æ•¸æ“šé–å®šã€ï¼Œä½ å¿…é ˆå‘¼å«ï¼š\n1. `query_ad_formats` (å› ç‚ºæåˆ°ã€Œæ ¼å¼ã€)\n2. `query_performance_metrics` (å› ç‚ºæåˆ°ã€Œæˆæ•ˆã€)\n3. `query_targeting_segments` (å› ç‚ºæåˆ°ã€Œæ•¸æ“šé–å®šã€)\n\nğŸš¨ **ç¦æ­¢äº‹é …**ï¼š\n- ä¸è¦é‡è¤‡å‘¼å« `resolve_entity` è¶…é 2 æ¬¡\n- ä¸è¦ä½¿ç”¨é™¤ '{entity_value}' ä»¥å¤–çš„å…¶ä»–é—œéµå­—\n- ä¸è¦æ¼æ‰ä½¿ç”¨è€…æŸ¥è©¢ä¸­æ˜ç¢ºæåˆ°çš„æ•¸æ“šé¡å‹"
                                            messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))
                                        else:
                                            # å…¶ä»–é¡å‹ï¼ˆclient, brand, agencyï¼‰ï¼šéœ€è¦ç²¾ç¢º ID
                                            guide_msg = f"ğŸ” RAG æ‰¾åˆ°ç›¸é—œå¯¦é«”: {entity_value} (é¡å‹: {entity_type}, åˆ†æ•¸: {top_result.get('score'):.2f})ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥: è«‹å†æ¬¡å‘¼å« `resolve_entity`ï¼Œä½¿ç”¨åƒæ•¸ `keyword='{entity_value}'` å’Œ `target_types=['{entity_type}']` ä¾†å–å¾—ç²¾ç¢ºçš„ IDã€‚"
                                            messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))
                                    else:
                                        # ç„¡æ³•è­˜åˆ¥çš„ filter_typeï¼Œè¿”å›æ‰€æœ‰çµæœè®“ LLM åˆ¤æ–·
                                        candidates_summary = "\n".join([f"- {r.get('value')} ({r.get('filter_type')}, åˆ†æ•¸: {r.get('score'):.2f})" for r in rag_data[:5]])
                                        guide_msg = f"ğŸ” RAG æ‰¾åˆ° {len(rag_data)} å€‹ç›¸é—œçµæœï¼š\n{candidates_summary}\n\nğŸ‘‰ è«‹æ ¹æ“šä½¿ç”¨è€…çš„æŸ¥è©¢éœ€æ±‚ï¼Œé¸æ“‡æœ€ç›¸é—œçš„å¯¦é«”ï¼Œä¸¦ä½¿ç”¨ `resolve_entity` å–å¾—ç²¾ç¢º IDã€‚"
                                        messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))

                # Log
                execution_logs.append({
                    "step": "retrieval",
                    "tool": tool_name,
                    "args": args,
                    "row_count": len(result.get("data", [])) if isinstance(result, dict) else 0
                })

                # [NEW] Add guidance for query_campaign_basic results
                if tool_name == "query_campaign_basic" and isinstance(result, dict) and result.get("data"):
                    campaign_ids = [row.get('campaign_id') for row in result.get("data", []) if row.get('campaign_id')]
                    if campaign_ids:
                        guide_msg = f"\n\nâœ… å·²å–å¾— {len(campaign_ids)} å€‹æ´»å‹•çš„åŸºæœ¬è³‡æ–™ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥ (Step 3): è«‹æ ¹æ“šä½¿ç”¨è€…æŸ¥è©¢éœ€æ±‚ï¼Œå‘¼å«ä»¥ä¸‹å·¥å…·ï¼š\n- `query_ad_formats(campaign_ids={json.dumps(campaign_ids[:10])})` - æŸ¥è©¢å»£å‘Šæ ¼å¼\n- `query_performance_metrics(cmp_ids={json.dumps(campaign_ids[:10])})` - æŸ¥è©¢æˆæ•ˆæ•¸æ“š"
                        content = json.dumps(result, ensure_ascii=False, default=str) + guide_msg
                    else:
                        content = json.dumps(result, ensure_ascii=False, default=str)
                else:
                    content = json.dumps(result, ensure_ascii=False, default=str)

                messages.append(ToolMessage(tool_call_id=tool_call["id"], content=content))

            except Exception as e:
                error_msg = f"Error executing {tool_name}: {e}"
                print(f"ERROR [Retriever] {error_msg}")
                messages.append(ToolMessage(tool_call_id=tool_call["id"], content=error_msg))

    return {
        "data_store": data_store,
        "resolved_entities": resolved_entities,
        "debug_logs": execution_logs
    }
