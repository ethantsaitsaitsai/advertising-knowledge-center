"""
Data Retriever Node for AKC Framework 3.0

Responsibilities:
1. Resolve Entities (Names -> IDs)
2. Execute SQL Queries (MySQL & ClickHouse)
3. Store raw results in state['data_store']
4. Pass control to DataReporter
"""
from typing import Dict, Any, List
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from config.llm import llm
from agent.state import AgentState
from tools.entity_resolver import resolve_entity
from tools.campaign_template_tool import (
    id_finder,
    query_campaign_basic,
    query_investment_budget,
    query_execution_budget,
    query_targeting_segments,
    execute_sql_template,
    query_industry_format_budget
)
from tools.performance_tools import query_unified_performance, query_format_benchmark
import json
from datetime import datetime

# Tools for Retrieval ONLY (No Pandas)
RETRIEVER_TOOLS = [
    resolve_entity,
    id_finder,
    query_campaign_basic,
    query_investment_budget,
    query_execution_budget,
    query_targeting_segments,
    execute_sql_template,
    query_industry_format_budget,
    query_unified_performance,
    query_format_benchmark
]

# Bind tools
llm_with_tools = llm.bind_tools(RETRIEVER_TOOLS)

RETRIEVER_SYSTEM_PROMPT = """ä½ æ˜¯ AKC æ™ºèƒ½åŠ©æ‰‹çš„æ•¸æ“šæª¢ç´¢å°ˆå®¶ (Data Retriever)ã€‚

**ä½ çš„æ ¸å¿ƒä»»å‹™**:
è² è²¬å¾è³‡æ–™åº«ä¸­æª¢ç´¢åŸå§‹æ•¸æ“šã€‚ä½ **ä¸è² è²¬**è¨ˆç®—ã€åˆä½µæˆ–ç•«è¡¨ï¼Œé€™äº›æ˜¯ Reporter çš„å·¥ä½œã€‚ä½ çš„ç›®æ¨™æ˜¯ç²¾æº–åœ°æ‰¾å‡ºç›¸é—œçš„ã€ŒIDã€ï¼Œä¸¦åˆ©ç”¨é€™äº› ID æ’ˆå–è©³ç´°å±¬æ€§ã€‚

**æ¨™æº–ä½œæ¥­æµç¨‹ (SOP)**:

**Step 1: æ¢ç´¢èˆ‡å®šä½ (Discovery)**
-ç•¶ä½¿ç”¨è€…æåˆ°ç‰¹å®šçš„å®¢æˆ¶ã€ç”¢æ¥­ã€æ ¼å¼æˆ–æ™‚é–“ç¯„åœæ™‚ï¼Œ**é¦–å…ˆ**å‘¼å« `id_finder`ã€‚
- `id_finder` æ˜¯ä½ çš„æ ¸å¿ƒå°èˆªå™¨ï¼Œå®ƒæœƒå›å‚³ç¬¦åˆæ¢ä»¶çš„æ‰€æœ‰ `cue_list_id` (åˆç´„), `campaign_id` (æ´»å‹•), å’Œ `plaid` (ç‰ˆä½)ã€‚
- **æ³¨æ„**: è‹¥ä½¿ç”¨è€…çµ¦çš„æ˜¯ã€Œåç¨±ã€(å¦‚ "æ‚ éŠå¡")ï¼Œè«‹å…ˆç”¨ `resolve_entity` è½‰æˆ IDï¼Œå†å‚³çµ¦ `id_finder`ã€‚

**Step 2: æ•¸æ“šæ’ˆå– (Data Fetching)**
- å–å¾— ID å¾Œï¼Œæ ¹æ“šä½¿ç”¨è€…éœ€æ±‚å‘¼å«å°æ‡‰çš„è©³ç´°å·¥å…· (å¯å¹³è¡Œå‘¼å«)ï¼š
  - **æƒ³çœ‹é ç®—/é€²å–®é‡‘é¡/æ ¼å¼é…ç½®** â†’ å‘¼å« `query_investment_budget(cue_list_ids=[...])`
  - **æƒ³çœ‹åŸ·è¡Œé‡‘é¡/å¯¦éš›èŠ±è²»** â†’ å‘¼å« `query_execution_budget(plaids=[...])`
  - **æƒ³çœ‹æˆæ•ˆ (CTR/VTR/ER)** â†’ å‘¼å« `query_unified_performance(plaids=[...], group_by=['ad_format_type'])`
  - **æƒ³çœ‹å—çœ¾/æ•¸æ“šé–å®š** â†’ å‘¼å« `query_targeting_segments(plaids=[...])`
  - **æƒ³çœ‹æ´»å‹•è©³ç´°è³‡è¨Š (åç¨±/æ—¥æœŸ)** â†’ å‘¼å« `query_campaign_basic(campaign_ids=[...])`

**ç‰¹æ®Šå ´æ™¯**:
- **ç”¢æ¥­/å¤§ç›¤çµ±è¨ˆ** (å¦‚ "æ±½è»Šç”¢æ¥­çš„æ ¼å¼ä½”æ¯”")ï¼š
  - ä¸éœ€è¦æŸ¥ IDï¼Œç›´æ¥ä½¿ç”¨ `query_industry_format_budget(dimension='industry', ...)`ã€‚
  - **è­¦å‘Š**: è«‹å‹¿å°‡æ­¤å·¥å…·ç”¨æ–¼æŸ¥è©¢ç‰¹å®šå®¢æˆ¶çš„æ˜ç´°ï¼Œå®ƒåªé©åˆçœ‹å¤§è¶¨å‹¢ã€‚

**å·¥å…·åƒæ•¸æŒ‡å—**:
- `id_finder`: å¿…é ˆæä¾› `start_date` èˆ‡ `end_date`ã€‚
- `query_unified_performance`: å»ºè­°ä½¿ç”¨ `plaids` é€²è¡Œç²¾æº–éæ¿¾ã€‚`group_by` åƒæ•¸ä¾éœ€æ±‚è¨­å®š (å¦‚ `['campaign_name', 'ad_format_type']`)ã€‚
- `query_investment_budget`: **å¿…é ˆ** ä½¿ç”¨ `cue_list_ids`ã€‚
- `query_execution_budget`: **å¿…é ˆ** ä½¿ç”¨ `plaids`ã€‚

**ç•¶å‰æ—¥æœŸ**: {current_date}

**æ ¸å¿ƒåŸå‰‡ (éµå¾‹)**:
- **ID ç‚ºç‹**: æ‹¿åˆ° ID å¾Œï¼Œå¾ŒçºŒæŸ¥è©¢ä¸€å¾‹ä½¿ç”¨ ID (List[int])ï¼Œåš´ç¦ä½¿ç”¨åç¨±ã€‚
- **é¿å…æ¿«ç”¨**: ä¸è¦å°åŒä¸€å€‹ ID é‡è¤‡å‘¼å«ç›¸åŒçš„å·¥å…·ã€‚
- **ç²¾æº–å›æ‡‰**: ç•¶ä½ æ”¶é›†å®Œæ‰€æœ‰å¿…è¦æ•¸æ“šå¾Œï¼Œè«‹å›è¦†ï¼šã€Œæ•¸æ“šæ”¶é›†å®Œç•¢ï¼Œè½‰äº¤å ±å‘Šè€…è™•ç†ã€‚ã€
"""

def data_retriever_node(state: AgentState) -> Dict[str, Any]:
    """
    Executes retrieval loop and accumulates data in state['data_store'].
    """
    # Initialize context
    now = datetime.now()
    current_date = now.strftime("%Y-%m-%d")

    routing_context = state.get("routing_context", {})
    original_query = routing_context.get("original_query", "")
    entity_keywords = routing_context.get("entity_keywords", [])

    # Initialize or Load Data Store
    data_store = state.get("data_store") or {}
    resolved_entities = state.get("resolved_entities") or []
    execution_logs = state.get("debug_logs") or []

    print(f"DEBUG [Retriever] Starting retrieval for: {original_query[:50]}...")

    # Build Messages
    messages = [
        SystemMessage(content=RETRIEVER_SYSTEM_PROMPT.format(current_date=current_date)),
        HumanMessage(content=f"æŸ¥è©¢è«‹æ±‚: {original_query}\nå¯¦é«”æç¤º: {entity_keywords}")
    ]

    # Re-inject resolved entities context if any
    if resolved_entities:
        context_lines = []
        for e in resolved_entities:
            e_type = e.get('type', 'unknown')
            e_id = e.get('id')
            e_name = e.get('name')
            context_lines.append(f"- {e_type.upper()} ID: {e_id} (åç¨±: {e_name})")

        entity_context = "å·²ç¢ºèªçš„å¯¦é«”è³‡è¨Šï¼š\n" + "\n".join(context_lines)
        messages.append(SystemMessage(content=entity_context))

    # Agent Loop
    tool_call_history = set()

    for i in range(10): # Max 10 steps for retrieval
        print(f"DEBUG [Retriever] Step {i+1}")
        response = llm_with_tools.invoke(messages)
        messages.append(response)

        if not response.tool_calls:
            print("DEBUG [Retriever] No more tool calls. Retrieval finished.")
            break

        for tool_call in response.tool_calls:
            tool_name = tool_call["name"]
            args = tool_call["args"]

            # 1. Skip if duplicate call
            call_key = f"{tool_name}:{json.dumps(args, sort_keys=True)}"
            if call_key in tool_call_history:
                print(f"DEBUG [Retriever] Skipping duplicate call: {call_key}")
                messages.append(ToolMessage(tool_call_id=tool_call["id"], content="Notice: This query was already executed. Skipping."))
                continue
            tool_call_history.add(call_key)

            # Execute
            tool_map = {t.name: t for t in RETRIEVER_TOOLS}
            func = tool_map.get(tool_name)

            if not func:
                messages.append(ToolMessage(tool_call_id=tool_call["id"], content="Error: Tool not found"))
                continue

            try:
                print(f"DEBUG [Retriever] Calling {tool_name} with {args}")
                result = func.invoke(args)

                # 2. Logic to store data (with Deduplication)
                if isinstance(result, dict) and "data" in result:
                    data = result.get("data")
                    if data and isinstance(data, list) and len(data) > 0:
                        if tool_name not in data_store:
                            data_store[tool_name] = []

                        # Deduplicate: Only add rows that aren't already there
                        existing_data_str = {json.dumps(row, sort_keys=True, default=str) for row in data_store[tool_name]}
                        new_rows = []
                        for row in data:
                            row_str = json.dumps(row, sort_keys=True, default=str)
                            if row_str not in existing_data_str:
                                new_rows.append(row)
                                existing_data_str.add(row_str)

                        if new_rows:
                            data_store[tool_name].extend(new_rows)
                            print(f"DEBUG [Retriever] Stored {len(new_rows)} NEW rows from {tool_name}")
                        else:
                            print(f"DEBUG [Retriever] All rows from {tool_name} were duplicates. Skipped.")

                        # Handle Entity Resolution specifically
                        if tool_name == "resolve_entity":
                            status = result.get("status")
                            if status in ["exact_match", "merged_match"]:
                                entity = result.get("data")
                                if isinstance(entity, list):
                                    resolved_entities.extend(entity)
                                else:
                                    resolved_entities.append(entity)
                                
                                # Guide: Use id_finder after resolution
                                guide_msg = f"âœ… å·²è§£æå¯¦é«”ã€‚ä¸‹ä¸€æ­¥: è«‹å‘¼å« `id_finder`ï¼Œå‚³å…¥ `client_ids` (æˆ–å…¶ä»–å°æ‡‰ ID) ä»¥åŠæŸ¥è©¢çš„æ™‚é–“ç¯„åœ `start_date`, `end_date`ã€‚"
                                messages.append(ToolMessage(tool_call_id=tool_call["id"], content=guide_msg))
                                continue

                # Log
                execution_logs.append({
                    "step": "retrieval",
                    "tool": tool_name,
                    "args": args,
                    "row_count": len(result.get("data", [])) if isinstance(result, dict) else 0
                })

                # [NEW] Add guidance for id_finder results
                if tool_name == "id_finder" and isinstance(result, dict) and result.get("data"):
                    rows = result.get("data", [])
                    # Extract ID lists
                    cue_list_ids = list(set(r['cue_list_id'] for r in rows if r.get('cue_list_id')))
                    campaign_ids = list(set(r['campaign_id'] for r in rows if r.get('campaign_id')))
                    plaids = list(set(r['plaid'] for r in rows if r.get('plaid')))
                    
                    if plaids:
                        guide_msg = f"\n\nâœ… å·²æ‰¾åˆ°ç›¸é—œ IDs (å…± {len(rows)} ç­†)ã€‚\nğŸ‘‰ ä¸‹ä¸€æ­¥: è«‹æ ¹æ“šéœ€æ±‚å¹³è¡Œå‘¼å«ä»¥ä¸‹å·¥å…·ï¼š\n"
                        guide_msg += f"- `query_investment_budget(cue_list_ids={json.dumps(cue_list_ids[:20])})` (æŸ¥é ç®—)\n"
                        guide_msg += f"- `query_execution_budget(plaids={json.dumps(plaids[:20])})` (æŸ¥åŸ·è¡Œé‡‘é¡)\n"
                        guide_msg += f"- `query_unified_performance(plaids={json.dumps(plaids[:20])}, group_by=['campaign_name'])` (æŸ¥æˆæ•ˆ)\n"
                        guide_msg += f"- `query_targeting_segments(plaids={json.dumps(plaids[:20])})` (æŸ¥å—çœ¾)\n"
                        content = json.dumps(result, ensure_ascii=False, default=str) + guide_msg
                    else:
                        content = json.dumps(result, ensure_ascii=False, default=str)
                else:
                    content = json.dumps(result, ensure_ascii=False, default=str)

                messages.append(ToolMessage(tool_call_id=tool_call["id"], content=content))

            except Exception as e:
                error_msg = f"Error executing {tool_name}: {e}"
                print(f"ERROR [Retriever] {error_msg}")
                messages.append(ToolMessage(tool_call_id=tool_call["id"], content=error_msg))

    return {
        "data_store": data_store,
        "resolved_entities": resolved_entities,
        "debug_logs": execution_logs
    }