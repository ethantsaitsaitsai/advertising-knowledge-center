
from langchain_core.messages import SystemMessage
from nodes.performance_agent import create_performance_agent
from schemas.state import AgentState

# Initialize the agent once
performance_runnable = create_performance_agent()

def performance_node(state: AgentState):
    """
    Executes the Performance Agent.
    """
    messages = list(state["messages"])
    
    # Inject Supervisor Instructions
    instructions = state.get("supervisor_instructions")
    if instructions:
        print(f"DEBUG [PerformanceNode] Supervisor Instructions: {instructions}")
        messages.append(SystemMessage(content=f"Supervisor Instructions: {instructions}"))
    
    # --- Context Injection: Pass Campaign IDs ---
    campaign_data = state.get("campaign_data")
    if campaign_data and "data" in campaign_data:
        # Extract IDs (cmpid)
        # The column name might be 'cmpid', 'id', or 'one_campaigns_id' depending on SQL output
        # We iterate to find a likely ID column.
        ids = []
        rows = campaign_data["data"]
        if rows:
            first_row = rows[0]
            # Try to find the ID key
            id_key = next((k for k in first_row.keys() if k.lower() in ['cmpid', 'id']), None)
            if id_key:
                ids = [row[id_key] for row in rows if row.get(id_key)]
        
        if ids:
            id_list_str = ", ".join(map(str, ids[:100])) # Limit to 100 IDs to avoid huge prompt
            if len(ids) > 100:
                id_list_str += "..."
            
            print(f"DEBUG [PerformanceNode] Injecting {len(ids)} IDs into context.")
            
            # Inject a system instruction
            system_hint = SystemMessage(content=f"""
[SYSTEM CONTEXT]
Campaign Data has been retrieved.
Available Campaign IDs: [{id_list_str}]
Total Count: {len(ids)}

Please use these IDs to query performance metrics using `query_performance_data`.
You MUST pass these IDs in the `ids_data` argument (or the tool will read from state if adapted).
Actually, just pass the raw IDs in the prompt context logic if the tool expects a list.
Wait, the tool `query_performance_data` expects `ids_data` (List[Dict]).
Since the tool call is generated by LLM, the LLM needs to pass this huge list?
NO. That's inefficient.

OPTIMIZATION:
The `query_performance_data` tool logic should be smart enough to read from the shared state if the LLM passes a placeholder or if the argument is missing.
BUT, for ReAct, the LLM MUST generate the arguments.
For now, we will rely on the LLM passing the IDs if they are few.
If they are many, this Approach might break due to Output Token Limit of the LLM generating the tool call.

TEMPORARY FIX:
We will inject the IDs so the LLM *knows* them.
If the list is too long, we might need a better tool design (e.g. `query_performance_data_from_context`).
For now, let's inject.
""")
            messages.append(system_hint)

    # Invoke the agent
    result = performance_runnable.invoke(
        {"messages": messages}
    )
    
    last_message = result["messages"][-1]
    
    # --- Optimization: Context Window Protection ---
    MAX_CONTENT_LENGTH = 2000
    if len(last_message.content) > MAX_CONTENT_LENGTH:
        print(f"DEBUG [PerformanceNode] Truncating output from {len(last_message.content)} chars.")
        last_message.content = last_message.content[:MAX_CONTENT_LENGTH] + "\n... [Output Truncated for Supervisor] ..."

    return {
        "messages": state["messages"] + [last_message]
    }
